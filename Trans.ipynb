{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    \n",
    "    def preprocess(self, resized):\n",
    "        ret = resized.astype('f4')\n",
    "        ret -= self.mean\n",
    "        ret /= (1.e-6+ self.std)\n",
    "        return  ret\n",
    "    \n",
    "    def predict(self, resized):\n",
    "        \"\"\"\n",
    "        @resized: image 40,40 already pre processed \n",
    "        \"\"\"         \n",
    "        self.net.blobs['data'].data[...] = cv2.split(resized)\n",
    "        prediction = self.net.forward()['Dense2'][0]\n",
    "        return prediction\n",
    "        \n",
    "    def __init__(self, protoTXTPath, weightsPath):\n",
    "        caffe.set_mode_cpu()\n",
    "        self.net = caffe.Net(protoTXTPath,weightsPath,caffe.TEST)\n",
    "        self.mean = cv2.imread('./trainMean.png').astype('float')\n",
    "        self.std  = cv2.imread('./trainSTD.png').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22493494 -0.24115832  0.18771622 -0.25451189  0.02025338 -0.02075372\n",
      " -0.23037848  0.14349605  0.20071335  0.13110712]\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(\"./vanilla_deploy.prototxt\",\"./vanillaCNN.caffemodel\")       #load caffe model and weights\n",
    "\n",
    "a=cv2.imread(\"./test.png\")\n",
    "a=cv2.resize(a,(40,40))                     #load test image\n",
    "\n",
    "img=predictor.preprocess(a)           #pre processing\n",
    "\n",
    "points=predictor.predict(img)       #predict facial landmark\n",
    "\n",
    "print(points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Draw landmarks in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 35.20832825  33.13173676  88.02767944  31.42247772  66.59243011\n",
      "  61.34352493  34.51155472  82.36749268  89.69130707  80.78170776]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "landmark=(points+0.5)*128\n",
    "print(landmark)\n",
    "\n",
    "a=cv2.resize(a,(128,128))\n",
    "\n",
    "cv2.circle(a,(landmark[0],landmark[1]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[2],landmark[3]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[4],landmark[5]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[6],landmark[7]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[8],landmark[9]),2,(0,255,0))\n",
    "\n",
    "# cv2.imshow(\"1\",a)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MXNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "model=mx.model.FeedForward.load('vanilla',1,num_batch_size=1)     #load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=np.zeros((1,3,40,40),dtype=np.float32)      #change chanels into shape[1,3,40,40]\n",
    "b[0,0,:,:]=img[:,:,0]\n",
    "b[0,1,:,:]=img[:,:,1]\n",
    "b[0,2,:,:]=img[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.22934215 -0.23023021  0.18563938 -0.24870965  0.01203199 -0.01072186\n",
      "  -0.22650576  0.15279464  0.19636042  0.13335897]]\n",
      "[ 34.64420319  34.53053284  87.76184082  32.16516495  65.54009247\n",
      "  62.62760162  35.00726318  83.55771637  89.13413239  81.06994629]\n"
     ]
    }
   ],
   "source": [
    "points=model.predict(b)\n",
    "print(points)\n",
    "\n",
    "landmark=(points+0.5)*128       #print landmarks\n",
    "print(landmark[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=cv2.imread(\"./test.png\")\n",
    "\n",
    "landmark=landmark[0]\n",
    "cv2.circle(a,(landmark[0],landmark[1]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[2],landmark[3]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[4],landmark[5]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[6],landmark[7]),2,(0,255,0))\n",
    "cv2.circle(a,(landmark[8],landmark[9]),2,(0,255,0))\n",
    "\n",
    "cv2.imwrite(\"landmark.jpg\",a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
